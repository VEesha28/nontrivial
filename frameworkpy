# @title Further
# Dengue Forecasting with SEIR-SEI-Control ODE and EnKF-RF Fusion

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
from scipy.integrate import solve_ivp
from filterpy.kalman import EnsembleKalmanFilter

# Load data
file_path = '/content/merged_cases_climate_mosqlient.csv'
df = pd.read_csv(file_path)
df['data_iniSE'] = pd.to_datetime(df['data_iniSE'])
df.set_index('data_iniSE', inplace=True)

# Define columns
climate_cols = ['tempmed', 'precip_tot_sum', 'umidmed']
target_col = 'casos_est'

# Create lags
for feat in [target_col] + climate_cols:
    for lag in range(1, 5):
        df[f'{feat}_lag{lag}'] = df[feat].shift(lag)

# Drop NA rows
lag_cols = [f'{feat}_lag{lag}' for feat in [target_col] + climate_cols for lag in range(1, 5)]
df.dropna(subset=lag_cols, inplace=True)

# Extract years from SE column
df['year'] = df['SE'].astype(str).str[:4].astype(int)

# Parameters - Added new control parameters and trans_wol
N_obs, N_mosq = 100000, 100000
init_params = {
    'alpha_h': 1/7, 'gamma_h': 1/7, 'mu_m': 1/10, 'nu_m': 1/10, 'alpha_m': 1/5,
    'beta0': 0.05, 'beta_temp': 0.005, 'beta_precip': 0.0005,
    'ν_vac': 0.0, 'ε_vac': 0.0, 'ν_wol': 0.0, 'μ_ctrl': 0.0, 'trans_wol': 0.1, # Initial values for new parameters
    'Tmin': 10.0, 'Tmax': 40.0, 'R0': 50.0, 'k_r': 0.1, 'beta_humid': 0.002 # Added to init_params for clarity, though estimated
}

# Briere and logistic functions (used for parameter estimation in this version)
def briere(T, Tmin, Tmax, c=1e-4):
    return np.maximum(c * T * (T - Tmin) * np.sqrt(np.maximum(Tmax - T, 0)), 0)

def logistic_rainfall(R, R0, k):
    # Clip input to exp to prevent overflow
    exp_input = -k * (R - R0)
    exp_input = np.clip(exp_input, -20, 20) # Clipping to a range that avoids overflow
    return 1 / (1 + np.exp(exp_input))

# Model function - Modified to accept humidity from climate, state is now 9 compartments
def seir_sei_control(t, state, params, climate):
    Sh, Eh, Ih, Rh, Vh, Sm, Em, Im, Wm = np.maximum(state, 0)
    Nh = Sh + Eh + Ih + Rh + Vh
    # Ensure Nh is not zero to prevent division errors
    Nh = max(Nh, 1)

    T, R, H = climate['tempmed'], climate['precip_tot_sum'], climate['umidmed']

    # Use estimated betas from params, combine with fixed params
    # Check if estimated parameters exist in params
    beta0 = params.get('beta0_est', params.get('beta0', 0.05)) # Use estimated if available, else initial
    beta_temp = params.get('beta_temp_est', params.get('beta_temp', 0.005))
    beta_precip = params.get('beta_precip_est', params.get('beta_precip', 0.0005))
    # Assuming Tmin, Tmax, R0, k_r, beta_humid are also estimated if beta0 etc are estimated
    Tmin = params.get('Tmin_est', params.get('Tmin', 10.0))
    Tmax = params.get('Tmax_est', params.get('Tmax', 40.0))
    R0 = params.get('R0_est', params.get('R0', 50.0))
    k_r = params.get('k_r_est', params.get('k_r', 0.1))
    beta_humid = params.get('beta_humid_est', params.get('beta_humid', 0.002))


    nu_vac = params['ν_vac']
    epsilon_vac = params['ε_vac']
    nu_wol = params['ν_wol']
    mu_ctrl = params['μ_ctrl']
    trans_wol = params['trans_wol']
    alpha_h = params['alpha_h']
    gamma_h = params['gamma_h']
    mu_m = params['mu_m']
    nu_m = params['nu_m']
    alpha_m = params['alpha_m']

    # Beta calculation using estimated parameters and climate inputs
    T_br = briere(T, Tmin, Tmax)
    R_eff = logistic_rainfall(R, R0, k_r)
    β = max(0, T_br * R_eff + beta_humid * H)


    λ_h = β * (Im + Wm * trans_wol) / Nh
    λ_m = β * Ih / Nh

    # ODE system for 9 compartments
    dSh = params['BIRTH_DEATH_RATE'] * N_obs - λ_h * Sh - params['BIRTH_DEATH_RATE'] * Sh - nu_vac * Sh
    dEh = λ_h * Sh - alpha_h * Eh - params['BIRTH_DEATH_RATE'] * Eh
    dIh = alpha_h * Eh - gamma_h * Ih - params['BIRTH_DEATH_RATE'] * Ih
    dRh = gamma_h * Ih - params['BIRTH_DEATH_RATE'] * Rh
    dVh = nu_vac * (Sh + Rh) - epsilon_vac * λ_h * Vh - params['BIRTH_DEATH_RATE'] * Vh # assuming vaccination for S and R compartments
    dSm = nu_m * N_mosq - λ_m * Sm - (mu_m + mu_ctrl + nu_wol) * Sm
    dEm = λ_m * Sm - (alpha_m + mu_m + mu_ctrl) * Em
    dIm = alpha_m * Em - (mu_m + mu_ctrl) * Im
    dWm = nu_wol * (Sm + Em + Im) - (mu_m + mu_ctrl) * Wm # assuming Wolbachia affects all mosquito compartments


    return [dSh, dEh, dIh, dRh, dVh, dSm, dEm, dIm, dWm]


# State size and noise
# State vector: Sh, Eh, Ih, Rh, Vh, Sm, Em, Im, Wm, Tmin, Tmax, R0, k_r, beta_humid (14 elements)
# Corrected state size to match the estimated parameters
init_state = np.array([
    N_obs * 0.99, N_obs * 0.005, N_obs * 0.005, 0, N_obs * 0.0, # Sh, Eh, Ih, Rh, Vh (5)
    N_mosq * 0.99, N_mosq * 0.005, N_mosq * 0.005, N_mosq * 0.0, # Sm, Em, Im, Wm (4)
    init_params['Tmin'], init_params['Tmax'], init_params['R0'], init_params['k_r'], init_params['beta_humid'] # Parameters to estimate (5)
]) # Total state size: 5 + 4 + 5 = 14

# Adjusted initial P for 14 parameters - Increased confidence in initial parameter values
init_P = np.diag([*(N_obs * 0.01,) * 5, *(N_mosq * 0.01,) * 4, 1.0, 1.0, 10.0, 0.1, 0.001]) # Reverted P slightly to allow more initial variability
# Adjusted Q for 14 parameters - Further reduced process noise for estimated parameters (indices 9 to 13) for more smoothing
Q = np.diag([10] * 9 + [1e-8, 1e-8, 1e-7, 1e-9, 1e-10]) # Further reduced noise significantly
n_ens = 100 # Increased ensemble size

# Measurement models - Adjusted to access Ih (index 2) from the 9-compartment state
def hx_base(state):
    # state[:9] contains the compartmental states
    return np.array([init_params['gamma_h'] * state[2]])

def hx_fusion(state):
     # state[:9] contains the compartmental states
     # Fusion measurement might use the estimated cases (from Ih) and maybe other state elements
     # For now, keep the structure but ensure correct indexing
     return np.array([init_params['gamma_h'] * state[2], 0.])


# EnKF fx - Modified to use seir_sei_control and handle 9 compartments + 5 betas
def fx(x, dt):
    # Ensure x is at least 2D
    x = np.atleast_2d(x)
    cl = fx.climate # Climate data for this step
    pf = fx.pf # Fixed parameters

    X = np.zeros_like(x)
    for i, s in enumerate(x):
        s = np.asarray(s)
        # Handle potential NaNs in state - replace with a small positive number
        if not np.isfinite(s).all():
            s = np.nan_to_num(s, nan=1e-5) # Use a very small positive number


        # Extract estimated parameters from state vector (indices 9 to 13)
        # Add clipping to estimated parameters to keep them within reasonable bounds
        Tmin_est = np.clip(s[9], 0.0, 30.0)
        Tmax_est = np.clip(s[10], 30.0, 50.0)
        R0_est = np.clip(s[11], 0.0, 200.0)
        k_r_est = np.clip(s[12], 0.0, 1.0)
        beta_humid_est = np.clip(s[13], 0.0, 0.1)


        estimated_params = {
            'Tmin_est': Tmin_est, 'Tmax_est': Tmax_est, 'R0_est': R0_est, 'k_r_est': k_r_est, 'beta_humid_est': beta_humid_est
        }

        # Combine fixed and estimated parameters for ODE
        # Pass all parameters needed by seir_sei_control, including fixed ones from pf
        ode_par = {
            **pf, # Includes fixed parameters like alpha_h, gamma_h, etc.
            **estimated_params, # Includes estimated parameters
            'BIRTH_DEATH_RATE': 1 / (70 * 52)
        }


        # Pass the first 9 elements of the state (compartmental states) to the ODE solver
        # ode_par and cl are passed as args
        sol = solve_ivp(seir_sei_control, [0, 7], s[:9], args=(ode_par, cl), t_eval=[7], method='RK45', events=None) # Use RK45 method

        # Update the state in X
        if sol.status == 0:
            X[i, :9] = sol.y[:, -1] # Update compartmental states
            # Apply clipping to compartmental states if needed (e.g., non-negativity is already handled by np.maximum)
        else:
            X[i, :9] = s[:9] # If ODE failed, keep the previous compartmental states

        # Update estimated parameters in X after clipping
        X[i, 9] = estimated_params['Tmin_est']
        X[i, 10] = estimated_params['Tmax_est']
        X[i, 11] = estimated_params['R0_est']
        X[i, 12] = estimated_params['k_r_est']
        X[i, 13] = estimated_params['beta_humid_est']

    # Ensure noise has the correct dimensions (14 elements)
    noise = np.random.multivariate_normal(np.zeros(X.shape[1]), Q, X.shape[0])
    return np.maximum(X + noise, 0) # Ensure non-negativity after adding noise


# Evaluate per year
results = {}
# Initialize lists to store all true and predicted values for overall metrics
all_true, all_preds = {'base': [], 'fus': []}, {'base': [], 'fus': []} # Removed rf from all_preds as it's not filtered
all_rf_preds = [] # Separate list for unfiltered RF predictions
all_rf_true = [] # Separate list for true values corresponding to RF predictions

years = df['year'].unique()

for year in years:
    yearly_df = df[df['year'] == year].copy()
    if len(yearly_df) < 20:
        continue

    train = yearly_df.iloc[:8]
    test = yearly_df.iloc[8:]

    if test.empty:
        continue

    X_train = train[lag_cols + climate_cols]
    y_train = train[target_col].shift(-1).dropna()
    X_train = X_train.loc[y_train.index]
    rf = RandomForestRegressor(n_estimators=100, random_state=42)
    if not X_train.empty:
        rf.fit(X_train, y_train)
    else:
        rf = None # Handle cases where RF cannot be trained


    # Initialize filters
    # Make sure init_state and init_P are correctly sized for the filter (14 elements)
    filter_init_state = init_state.copy()
    filter_init_P = init_P.copy()

    enkf_base = EnsembleKalmanFilter(x=filter_init_state, P=filter_init_P, dim_z=1, dt=7.0, N=n_ens, fx=lambda x, dt: x, hx=hx_base)
    enkf_base.Q = Q # Use the defined Q
    enkf_base.R = np.array([[200.]]) # Increased R for base filter for more smoothing
    enkf_base.ensembles = filter_init_state.copy() + np.random.multivariate_normal(np.zeros(len(filter_init_state)), filter_init_P, n_ens)

    enkf_fus = EnsembleKalmanFilter(x=filter_init_state.copy(), P=filter_init_P.copy(), dim_z=2, dt=7.0, N=n_ens, fx=lambda x, dt: x, hx=hx_fusion)
    enkf_fus.Q = Q # Use the defined Q
    enkf_fus.R = np.diag([200., 300.]) # Increased R for fusion filter for more smoothing
    enkf_fus.ensembles = filter_init_state.copy() + np.random.multivariate_normal(np.zeros(len(filter_init_state)), filter_init_P, n_ens)

    forecast = {'true': [], 'base': [], 'fus': [], 'rf': []}

    for i in range(len(test) - 1):
        t_idx = test.index[i]
        fut_idx = test.index[i + 1]

        # Ensure current data exists
        if t_idx not in df.index:
            continue

        obs = df.loc[t_idx, target_col]
        cl = df.loc[t_idx, climate_cols].to_dict()

        if any(pd.isna(val) for val in cl.values()):
            print(f"Skipping update for {t_idx} due to missing climate data.")
            continue


        fx.climate = cl
        fx.pf = init_params

        enkf_base.fx = fx
        enkf_fus.fx = fx

        enkf_base.predict()
        enkf_base.update(np.array([obs]))

        rf_pred = np.nan
        if rf is not None and t_idx in df.index and not df.loc[[t_idx], lag_cols + climate_cols].isnull().values.any():
          rf_pred = rf.predict(df.loc[[t_idx], lag_cols + climate_cols])[0]

        enkf_fus.predict()
        if not np.isnan(rf_pred):
           enkf_fus.update(np.array([obs, rf_pred]))
        else:
           enkf_fus.update(np.array([obs, 0]), R=np.array([[200., 0.], [0., 1e10]])) # Set very large R for RF, using updated R for obs


        # --- Forecasting and Aggregation for Overall Metrics ---
        if fut_idx not in df.index:
            for m in ['base', 'fus', 'rf']:
                forecast[m].append(np.nan)
            forecast['true'].append(np.nan)
            continue

        true_val = df.loc[fut_idx, target_col]
        forecast['true'].append(true_val)

        future_clim = df.loc[fut_idx, climate_cols].to_dict()
        if any(pd.isna(val) for val in future_clim.values()):
             for m in ['base', 'fus', 'rf']:
                forecast[m].append(np.nan)
             continue

        forecast_clim = future_clim

        for key, enkf in [('base', enkf_base), ('fus', enkf_fus)]:
            s = enkf.x.copy()
            estimated_params = {
                'Tmin_est': s[9], 'Tmax_est': s[10], 'R0_est': s[11], 'k_r_est': s[12], 'beta_humid_est': s[13]
            }
            ode_par = {
                **init_params,
                **estimated_params,
                'BIRTH_DEATH_RATE': 1 / (70 * 52)
            }
            sol = solve_ivp(seir_sei_control, [0, 7], s[:9], args=(ode_par, forecast_clim), t_eval=[7], method='RK45', events=None)
            pred = init_params['gamma_h'] * sol.y[2, -1] if sol.status == 0 else np.nan
            forecast[key].append(max(pred, 0) if not np.isnan(pred) else np.nan)


        rf_pred_next = np.nan
        if rf is not None and t_idx in df.index and not df.loc[[t_idx], lag_cols + climate_cols].isnull().values.any():
             rf_pred_next = rf.predict(df.loc[[t_idx], lag_cols + climate_cols])[0]

        forecast['rf'].append(max(rf_pred_next, 0) if not np.isnan(rf_pred_next) else np.nan)


    # --- Evaluation ---
    print(f"\n📊 Evaluation for {year}:")
    for m in ['base', 'fus', 'rf']:
        min_len = min(len(forecast['true']), len(forecast[m]))
        y = np.array(forecast['true'][:min_len])
        f = np.array(forecast[m][:min_len])

        valid = ~np.isnan(f) & ~np.isnan(y)
        if valid.sum() > 0:
            mae = mean_absolute_error(y[valid], f[valid])
            rmse = np.sqrt(mean_squared_error(y[valid], f[valid]))

            denominator = y[valid] + 1e-5
            accuracy_vals = np.abs(f[valid] - y[valid]) / denominator
            pct_acc = 100 - np.mean(accuracy_vals) * 100 if len(accuracy_vals) > 0 else np.nan

            print(f"  {m.upper()}: MAE = {mae:.2f}, RMSE = {rmse:.2f}, Avg Accuracy = {pct_acc:.2f}%")

            if len(y) > 0 and np.max(y) > 0:
                true_peak_idx_in_forecast = np.argmax(y)
                predicted_peak_idx = np.argmax(f)

                if true_peak_idx_in_forecast < len(forecast['true']) and predicted_peak_idx < len(forecast[m]):
                    true_peak_test_index = true_peak_idx_in_forecast + 1
                    predicted_peak_test_index = predicted_peak_idx + 1

                    if true_peak_test_index < len(test.index) and predicted_peak_test_index < len(test.index):
                        true_peak_date = test.index[true_peak_test_index]
                        predicted_peak_date = test.index[predicted_peak_test_index]
                        weeks_off = np.abs((predicted_peak_date - true_peak_date).days / 7.0)
                        print(f"    Peak Week Timing Error: True Peak Week Index (Test Set) = {true_peak_test_index}, Predicted Peak Week Index (Forecast List) = {predicted_peak_idx}, Weeks Off = {weeks_off:.2f}")
                    else:
                         print("    Peak Week Timing Error: Could not determine valid peak week indices for date calculation.")
                else:
                    print("    Peak Week Timing Error: Could not determine valid peak week indices in forecast list.")
            elif len(y) > 0 and np.max(y) == 0:
                 print("    Peak Week Timing Error: True peak is 0, skipping peak week error calculation.")
            else:
                print("    Peak Week Timing Error: Not enough data in test set to identify peak week.")
        else:
            print(f"  {m.upper()}: No valid forecasts for evaluation.")

    for m in ['base', 'fus', 'rf']:
         min_len = min(len(forecast['true']), len(forecast[m]))
         y = np.array(forecast['true'][:min_len])
         f = np.array(forecast[m][:min_len])
         valid = ~np.isnan(f) & ~np.isnan(y)

         # Separate RF predictions for overall aggregation as it's not filtered
         if m == 'rf':
             all_rf_true.extend(y[valid])
             all_rf_preds.extend(f[valid])
         else:
             all_true[m].extend(y[valid])
             all_preds[m].extend(f[valid])


    # --- Optional: Plotting ---
    plt.figure(figsize=(12, 5))
    plot_len = min(len(test.index) - 1, len(forecast['true']))
    if plot_len > 0:
      plot_indices = test.index[1:plot_len+1]
      if len(plot_indices) == len(forecast['true'][:plot_len]):
          plt.plot(plot_indices, forecast['true'][:plot_len], label='True Cases', marker='o')
          for m in ['base', 'fus', 'rf']:
              data_to_plot = np.array(forecast[m][:plot_len])
              plt.plot(plot_indices[~np.isnan(data_to_plot)], data_to_plot[~np.isnan(data_to_plot)], label=f'{m.upper()}', linestyle='--')
          plt.title(f'1-Week Ahead Dengue Case Forecast for {year}')
          plt.xlabel('Date')
          plt.ylabel('Estimated Cases')
          plt.legend()
          plt.grid(True)
          plt.show()
      else:
          print(f"Plotting data length mismatch for {year}")
    else:
      print(f"Not enough data to plot for {year}")


print("\n📊 Summary by year")
dfres = pd.DataFrame(results)
if not dfres.empty:
    print(dfres.pivot(index='year', columns='model', values='rmse').round(2))
else:
    print("No yearly results to summarize.")

print("\n\U0001F4CA Overall Accuracy Across All Years:")
# Evaluate EnKF models
for m in ['base', 'fus']:
    y_true_all = np.array(all_true[m])
    y_pred_all = np.array(all_preds[m])

    if len(y_true_all) > 0 and len(y_true_all) == len(y_pred_all):
        valid_all = ~np.isnan(y_pred_all) & ~np.isnan(y_true_all)

        if valid_all.sum() > 0:
            mae = mean_absolute_error(y_true_all[valid_all], y_pred_all[valid_all])
            rmse = np.sqrt(mean_squared_error(y_true_all[valid_all], y_pred_all[valid_all]))
            denominator = y_true_all[valid_all] + 1e-5
            accuracy_vals = np.abs(y_pred_all[valid_all] - y_true_all[valid_all]) / denominator
            pct_acc = 100 - np.mean(accuracy_vals) * 100 if len(accuracy_vals) > 0 else np.nan
            print(f"{m.upper()}: MAE={mae:.2f}, RMSE={rmse:.2f}, Accuracy={pct_acc:.2f}%")
        else:
            print(f"{m.upper()}: No valid overall forecasts for evaluation.")
    else:
        print(f"{m.upper()}: Not enough data or data length mismatch for overall evaluation.")

# Evaluate RF separately
y_true_rf = np.array(all_rf_true)
y_pred_rf = np.array(all_rf_preds)
if len(y_true_rf) > 0 and len(y_true_rf) == len(y_pred_rf):
    valid_rf = ~np.isnan(y_pred_rf) & ~np.isnan(y_true_rf)
    if valid_rf.sum() > 0:
        mae_rf = mean_absolute_error(y_true_rf[valid_rf], y_pred_rf[valid_rf])
        rmse_rf = np.sqrt(mean_squared_error(y_true_rf[valid_rf], y_pred_rf[valid_rf]))
        denominator_rf = y_true_rf[valid_rf] + 1e-5
        accuracy_vals_rf = np.abs(y_pred_rf[valid_rf] - y_true_rf[valid_rf]) / denominator_rf
        pct_acc_rf = 100 - np.mean(accuracy_vals_rf) * 100 if len(accuracy_vals_rf) > 0 else np.nan
        print(f"RF: MAE={mae_rf:.2f}, RMSE={rmse_rf:.2f}, Accuracy={pct_acc_rf:.2f}%")
    else:
        print(f"RF: No valid overall forecasts for evaluation.")
else:
    print(f"RF: Not enough data or data length mismatch for overall evaluation.")
